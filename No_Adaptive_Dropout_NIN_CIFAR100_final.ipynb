{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"No_Adaptive_Dropout_NIN_CIFAR100_final.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VouTljcpLD-A","colab_type":"text"},"source":["# Installing desired version of fastai - pytorch"]},{"cell_type":"code","metadata":{"id":"Y0Tf08U0r5GP","colab_type":"code","colab":{}},"source":["!pip install fastai==1.0.54 > /dev/null"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6VmFz6IJKM45","colab_type":"text"},"source":["# Setting up Environment to get reproducible results\n","\n","[** Didn't set num_workers as 1]\n","\n","Ref : https://docs.fast.ai/dev/test.html#getting-reproducible-results"]},{"cell_type":"code","metadata":{"id":"APQjxSSkKKXZ","colab_type":"code","colab":{}},"source":["seed = 42\n","\n","# python RNG\n","import random\n","random.seed(seed)\n","\n","# pytorch RNGs\n","import torch\n","torch.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n","\n","# numpy RNG\n","import numpy as np\n","np.random.seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fv4c2zj4J0fG","colab_type":"text"},"source":["# Loading required packages\n","\n","(Some packages can be removed, as I have carried out other operations that are not part of this release)"]},{"cell_type":"code","metadata":{"id":"oZCzCpUDsTsc","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import shutil as sh\n","import os\n","\n","from fastai.layers import *\n","from fastai.torch_core import *\n","\n","from fastai.vision import *\n","from fastai.callbacks.csv_logger import CSVLogger\n","from fastai.callbacks.hooks import *\n","\n","torch.backends.cudnn.benchmark = True\n","\n","from fastai.torch_core import *\n","from fastai.callback import *\n","from fastai.callbacks import *\n","from fastai.basic_train import *\n","from fastai.basic_data import *"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"REEHRBQmLKbz","colab_type":"text"},"source":["# Downloading CIFAR100 Dataset"]},{"cell_type":"code","metadata":{"id":"gyz_iBnxsYcv","colab_type":"code","colab":{}},"source":["path = untar_data(URLs.CIFAR_100)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Co1a_MdlLUVR","colab_type":"text"},"source":["# Parameters and Dataloader"]},{"cell_type":"code","metadata":{"id":"RZ8em3bksbBV","colab_type":"code","colab":{}},"source":["bs = 128\n","epochs = 50\n","metrics = [accuracy, error_rate, top_k_accuracy]\n","\n","loss_func = nn.CrossEntropyLoss()\n","\n","base_lr = 0.1\n","momentum= 0.9\n","w_decay = 0.0001\n","\n","opt_func = partial (optim.SGD, momentum=0.9)\n","\n","result_path = '/content/sample_data/activation/results/'\n","final_path = \"/content/drive/'My Drive'/activation/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HfADxASeskWy","colab_type":"code","colab":{}},"source":["ds_tfms = ([ *rand_pad(4, 32), flip_lr(p=0.5)], [])\n","data = ImageDataBunch.from_folder(path, valid='test', bs=bs ,ds_tfms = ds_tfms , val_bs =100).normalize(cifar_stats)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BCD1ZZRXLdB9","colab_type":"text"},"source":["# Modified NIN network\n","\n","Official Implementation\n","\n","https://gist.github.com/mavenlin/e56253735ef32c3c296d#file-solver-prototxt\n","\n","Our implementation is based on \n","\n","https://github.com/jiecaoyu/pytorch-nin-cifar10"]},{"cell_type":"code","metadata":{"id":"uQyEdkqpsrI0","colab_type":"code","colab":{}},"source":["class Net(nn.Module):\n","  def __init__(self):\n","    super(Net, self).__init__()\n","    self.num_classes = 100\n","    self.classifier = nn.Sequential(\n","                      nn.Conv2d(3, 192, kernel_size=5, stride=1, padding=2),\n","                      nn.ReLU(inplace=True),\n","                      nn.Conv2d(192, 160, kernel_size=1, stride=1, padding=0),\n","                      nn.ReLU(inplace=True),\n","                      nn.Conv2d(160,  96, kernel_size=1, stride=1, padding=0),\n","                      nn.ReLU(inplace=True),\n","                      nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","                      nn.Dropout(0.5),\n","\n","                      nn.Conv2d(96, 192, kernel_size=5, stride=1, padding=2),\n","                      nn.ReLU(inplace=True),\n","                      nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n","                      nn.ReLU(inplace=True),\n","                      nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n","                      nn.ReLU(inplace=True),\n","                      nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n","                      nn.Dropout(0.5),\n","\n","                      nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1),\n","                      nn.ReLU(inplace=True),\n","                      nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n","                      nn.ReLU(inplace=True),\n","                      nn.Conv2d(192,  self.num_classes , kernel_size=1, stride=1, padding=0),\n","                      nn.ReLU(inplace=True),\n","                      nn.AvgPool2d(kernel_size=8, stride=1, padding=0),\n","                      )\n","\n","  def forward(self, x):\n","    x = self.classifier(x)\n","    x = x.view(x.size(0), self.num_classes)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ObXs8cj2L5Io","colab_type":"text"},"source":["# Initializing weights and bias"]},{"cell_type":"code","metadata":{"id":"HcYid_IfMHzD","colab_type":"code","colab":{}},"source":["model = Net()\n","model.cuda()\n","\n","pretrained=False\n","if pretrained:\n","    params = pickle.load(open('data/params', 'r'))\n","    index = -1\n","    for m in model.modules():\n","        if isinstance(m, nn.Conv2d):\n","            index = index + 1\n","            weight = torch.from_numpy(params[index])\n","            m.weight.data.copy_(weight)\n","            index = index + 1\n","            bias = torch.from_numpy(params[index])\n","            m.bias.data.copy_(bias)\n","else:\n","    for m in model.modules():\n","        if isinstance(m, nn.Conv2d):\n","            m.weight.data.normal_(0, 0.05)\n","            m.bias.data.normal_(0, 0.0)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FMfiYInuMOXv","colab_type":"text"},"source":["# Splitting Model into sections for discriminative learning"]},{"cell_type":"code","metadata":{"id":"G2NQVSuRaiDz","colab_type":"code","colab":{}},"source":["learn = Learner(data, model, loss_func= loss_func, opt_func = opt_func ,metrics=metrics).mixup()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UBs1iGqzsuKv","colab_type":"code","colab":{}},"source":["learn.split([[ learn.model.classifier[0:20]], [learn.model.classifier[20] ]])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hnLRNWL9MToc","colab_type":"text"},"source":["# Decalring Step Dropout as Callback\n","\n"]},{"cell_type":"code","metadata":{"id":"byf9ZSraA5MZ","colab_type":"code","colab":{}},"source":["class Drop_Activations(LearnerCallback):\n","  train_flag = False\n","  \n","  def on_train_begin(self, **kwargs):\n","    \"Initialize stats.\"\n","    super().on_train_begin(**kwargs)\n","    self.train_flag = True\n","    \n","  def on_epoch_begin(self, **kwargs):\n","    if (self.train_flag):\n","      epoch_num = kwargs['epoch']\n","      epoch_tot = kwargs['n_epochs']\n","\n","      child = children(self.model)[0]\n","      for item in child:\n","        if isinstance(item, nn.Dropout):\n","          item.p = (epoch_num  / epoch_tot) * 0.5\n","\n","  def on_train_end(self, **kwargs):\n","    \"Initialize stats.\"\n","    super().on_train_begin(**kwargs)\n","    self.train_flag = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3usmfeiZMu31","colab_type":"text"},"source":["# Not using the step dropout in this notebook\n","\n","[Check the other notebook for results when it is used]"]},{"cell_type":"code","metadata":{"id":"s7GkZ8ajMqjL","colab_type":"code","colab":{}},"source":["# learn.callbacks += [ Drop_Activations(learn) ]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B5fz5C-KM3On","colab_type":"text"},"source":["# Running the Network"]},{"cell_type":"code","metadata":{"id":"P48QhLSTKQWL","colab_type":"code","outputId":"0801359b-0079-41ae-c0c8-4ae29552bf62","executionInfo":{"status":"ok","timestamp":1563220284559,"user_tz":-330,"elapsed":1330916,"user":{"displayName":"shuba shri","photoUrl":"https://lh3.googleusercontent.com/-6mf_1I_GK0M/AAAAAAAAAAI/AAAAAAAAAAw/L162wbYPd1w/s64/photo.jpg","userId":"07429367993324851323"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["learn.fit( 40 ,  lr= (1 * base_lr , 0.1 * base_lr) , wd = (2 * w_decay , 1 *w_decay))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>error_rate</th>\n","      <th>top_k_accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>4.501927</td>\n","      <td>4.445611</td>\n","      <td>0.028300</td>\n","      <td>0.971700</td>\n","      <td>0.138400</td>\n","      <td>00:33</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>4.338028</td>\n","      <td>4.208964</td>\n","      <td>0.058900</td>\n","      <td>0.941100</td>\n","      <td>0.215200</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>4.152569</td>\n","      <td>3.931767</td>\n","      <td>0.092000</td>\n","      <td>0.908000</td>\n","      <td>0.289400</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>4.032187</td>\n","      <td>3.821307</td>\n","      <td>0.111400</td>\n","      <td>0.888600</td>\n","      <td>0.337600</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>3.895887</td>\n","      <td>3.583205</td>\n","      <td>0.144400</td>\n","      <td>0.855600</td>\n","      <td>0.395800</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>3.808122</td>\n","      <td>3.455586</td>\n","      <td>0.168200</td>\n","      <td>0.831800</td>\n","      <td>0.441400</td>\n","      <td>00:33</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>3.694743</td>\n","      <td>3.352527</td>\n","      <td>0.189000</td>\n","      <td>0.811000</td>\n","      <td>0.466000</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>3.561748</td>\n","      <td>3.108771</td>\n","      <td>0.235800</td>\n","      <td>0.764200</td>\n","      <td>0.534000</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>3.477460</td>\n","      <td>2.835093</td>\n","      <td>0.288300</td>\n","      <td>0.711700</td>\n","      <td>0.600700</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>3.366826</td>\n","      <td>2.754434</td>\n","      <td>0.302800</td>\n","      <td>0.697200</td>\n","      <td>0.620600</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>3.322467</td>\n","      <td>2.750605</td>\n","      <td>0.303600</td>\n","      <td>0.696400</td>\n","      <td>0.624700</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>3.247287</td>\n","      <td>2.647890</td>\n","      <td>0.328200</td>\n","      <td>0.671800</td>\n","      <td>0.649200</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>3.139021</td>\n","      <td>2.450062</td>\n","      <td>0.368700</td>\n","      <td>0.631300</td>\n","      <td>0.686200</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>3.112669</td>\n","      <td>2.436718</td>\n","      <td>0.375000</td>\n","      <td>0.625000</td>\n","      <td>0.688900</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>3.050693</td>\n","      <td>2.241415</td>\n","      <td>0.408000</td>\n","      <td>0.592000</td>\n","      <td>0.730900</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>3.005463</td>\n","      <td>2.202413</td>\n","      <td>0.429200</td>\n","      <td>0.570800</td>\n","      <td>0.729800</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>2.934282</td>\n","      <td>2.142215</td>\n","      <td>0.443900</td>\n","      <td>0.556100</td>\n","      <td>0.748200</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>2.932855</td>\n","      <td>2.151173</td>\n","      <td>0.444500</td>\n","      <td>0.555500</td>\n","      <td>0.746200</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>2.897143</td>\n","      <td>2.123438</td>\n","      <td>0.441900</td>\n","      <td>0.558100</td>\n","      <td>0.754000</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>2.827679</td>\n","      <td>2.026937</td>\n","      <td>0.464800</td>\n","      <td>0.535200</td>\n","      <td>0.770500</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>2.809739</td>\n","      <td>2.001617</td>\n","      <td>0.472300</td>\n","      <td>0.527700</td>\n","      <td>0.777300</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>2.774648</td>\n","      <td>2.012407</td>\n","      <td>0.472600</td>\n","      <td>0.527400</td>\n","      <td>0.770500</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>2.741287</td>\n","      <td>1.940810</td>\n","      <td>0.489700</td>\n","      <td>0.510300</td>\n","      <td>0.786800</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>2.729116</td>\n","      <td>1.892020</td>\n","      <td>0.505400</td>\n","      <td>0.494600</td>\n","      <td>0.795100</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>2.726883</td>\n","      <td>1.936776</td>\n","      <td>0.494900</td>\n","      <td>0.505100</td>\n","      <td>0.785900</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>2.685188</td>\n","      <td>1.871126</td>\n","      <td>0.505400</td>\n","      <td>0.494600</td>\n","      <td>0.802800</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>2.663661</td>\n","      <td>1.824282</td>\n","      <td>0.516900</td>\n","      <td>0.483100</td>\n","      <td>0.804800</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>2.648610</td>\n","      <td>1.794944</td>\n","      <td>0.523800</td>\n","      <td>0.476200</td>\n","      <td>0.812700</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>2.640592</td>\n","      <td>1.813224</td>\n","      <td>0.521200</td>\n","      <td>0.478800</td>\n","      <td>0.810100</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>2.609090</td>\n","      <td>1.839646</td>\n","      <td>0.508000</td>\n","      <td>0.492000</td>\n","      <td>0.806300</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>2.620150</td>\n","      <td>1.811276</td>\n","      <td>0.522300</td>\n","      <td>0.477700</td>\n","      <td>0.804200</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>2.589757</td>\n","      <td>1.798177</td>\n","      <td>0.527700</td>\n","      <td>0.472300</td>\n","      <td>0.808000</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>2.595758</td>\n","      <td>1.755634</td>\n","      <td>0.535600</td>\n","      <td>0.464400</td>\n","      <td>0.816800</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>2.569854</td>\n","      <td>1.721678</td>\n","      <td>0.538500</td>\n","      <td>0.461500</td>\n","      <td>0.823000</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>2.549494</td>\n","      <td>1.739194</td>\n","      <td>0.531600</td>\n","      <td>0.468400</td>\n","      <td>0.823100</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>2.553139</td>\n","      <td>1.694710</td>\n","      <td>0.553700</td>\n","      <td>0.446300</td>\n","      <td>0.827400</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>2.528908</td>\n","      <td>1.674510</td>\n","      <td>0.554200</td>\n","      <td>0.445800</td>\n","      <td>0.833600</td>\n","      <td>00:31</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>2.504076</td>\n","      <td>1.655046</td>\n","      <td>0.557700</td>\n","      <td>0.442300</td>\n","      <td>0.832100</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>2.516309</td>\n","      <td>1.707768</td>\n","      <td>0.552900</td>\n","      <td>0.447100</td>\n","      <td>0.826400</td>\n","      <td>00:31</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>2.478166</td>\n","      <td>1.725992</td>\n","      <td>0.550100</td>\n","      <td>0.449900</td>\n","      <td>0.822300</td>\n","      <td>00:32</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"pKMNgGnbM7_r","colab_type":"text"},"source":["# Results "]},{"cell_type":"code","metadata":{"id":"oenZFegWLfYX","colab_type":"code","outputId":"682788bc-5118-42cb-f929-d5772c83cf57","executionInfo":{"status":"ok","timestamp":1563220288478,"user_tz":-330,"elapsed":31,"user":{"displayName":"shuba shri","photoUrl":"https://lh3.googleusercontent.com/-6mf_1I_GK0M/AAAAAAAAAAI/AAAAAAAAAAw/L162wbYPd1w/s64/photo.jpg","userId":"07429367993324851323"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["learn.validate()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1.7259924, tensor(0.5501), tensor(0.4499), tensor(0.8223)]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"sGDkG47HNAvS","colab_type":"text"},"source":["# Best Results :\n","\n","[Obtained during trial run. I hope the variation is minimal across multiple runs]\n","\n","\n","> train_loss --------------------------------- 2.478166\n","\n","> valid_loss --------------------------------- 1.655046 \n","\n","> accuracy ---------------------------------- 0.5577 \n","\n","> error_rate --------------------------------- 0.4423 \n","\n","> top_k_accuracy -----------------------  0.8336"]}]}