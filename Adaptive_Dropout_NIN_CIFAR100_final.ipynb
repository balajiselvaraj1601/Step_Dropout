{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NIN_CIFAR100_final.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VouTljcpLD-A","colab_type":"text"},"source":["# Installing desired version of fastai - pytorch"]},{"cell_type":"code","metadata":{"id":"Y0Tf08U0r5GP","colab_type":"code","colab":{}},"source":["!pip install fastai==1.0.54 > /dev/null"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6VmFz6IJKM45","colab_type":"text"},"source":["# Setting up Environment to get reproducible results\n","\n","[** Didn't set num_workers as 1]\n","\n","Ref : https://docs.fast.ai/dev/test.html#getting-reproducible-results"]},{"cell_type":"code","metadata":{"id":"APQjxSSkKKXZ","colab_type":"code","colab":{}},"source":["seed = 42\n","\n","# python RNG\n","import random\n","random.seed(seed)\n","\n","# pytorch RNGs\n","import torch\n","torch.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n","\n","# numpy RNG\n","import numpy as np\n","np.random.seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fv4c2zj4J0fG","colab_type":"text"},"source":["# Loading required packages\n","\n","(Some packages can be removed, as I have carried out other operations that are not part of this release)"]},{"cell_type":"code","metadata":{"id":"oZCzCpUDsTsc","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import shutil as sh\n","import os\n","\n","from fastai.layers import *\n","from fastai.torch_core import *\n","\n","from fastai.vision import *\n","from fastai.callbacks.csv_logger import CSVLogger\n","from fastai.callbacks.hooks import *\n","\n","torch.backends.cudnn.benchmark = True\n","\n","from fastai.torch_core import *\n","from fastai.callback import *\n","from fastai.callbacks import *\n","from fastai.basic_train import *\n","from fastai.basic_data import *"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"REEHRBQmLKbz","colab_type":"text"},"source":["# Downloading CIFAR100 Dataset"]},{"cell_type":"code","metadata":{"id":"gyz_iBnxsYcv","colab_type":"code","colab":{}},"source":["path = untar_data(URLs.CIFAR_100)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Co1a_MdlLUVR","colab_type":"text"},"source":["# Parameters and Dataloader"]},{"cell_type":"code","metadata":{"id":"RZ8em3bksbBV","colab_type":"code","colab":{}},"source":["bs = 128\n","epochs = 50\n","metrics = [accuracy, error_rate, top_k_accuracy]\n","\n","loss_func = nn.CrossEntropyLoss()\n","\n","base_lr = 0.1\n","momentum= 0.9\n","w_decay = 0.0001\n","\n","opt_func = partial (optim.SGD, momentum=0.9)\n","\n","result_path = '/content/sample_data/activation/results/'\n","final_path = \"/content/drive/'My Drive'/activation/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HfADxASeskWy","colab_type":"code","colab":{}},"source":["ds_tfms = ([ *rand_pad(4, 32), flip_lr(p=0.5)], [])\n","data = ImageDataBunch.from_folder(path, valid='test', bs=bs ,ds_tfms = ds_tfms , val_bs =100).normalize(cifar_stats)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BCD1ZZRXLdB9","colab_type":"text"},"source":["# Modified NIN network\n","\n","Official Implementation\n","\n","https://gist.github.com/mavenlin/e56253735ef32c3c296d#file-solver-prototxt\n","\n","Our implementation is based on \n","\n","https://github.com/jiecaoyu/pytorch-nin-cifar10"]},{"cell_type":"code","metadata":{"id":"uQyEdkqpsrI0","colab_type":"code","colab":{}},"source":["class Net(nn.Module):\n","  def __init__(self):\n","    super(Net, self).__init__()\n","    self.num_classes = 100\n","    self.classifier = nn.Sequential(\n","                      nn.Conv2d(3, 192, kernel_size=5, stride=1, padding=2),\n","                      nn.ReLU(inplace=True),\n","                      nn.Conv2d(192, 160, kernel_size=1, stride=1, padding=0),\n","                      nn.ReLU(inplace=True),\n","                      nn.Conv2d(160,  96, kernel_size=1, stride=1, padding=0),\n","                      nn.ReLU(inplace=True),\n","                      nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","                      nn.Dropout(0.5),\n","\n","                      nn.Conv2d(96, 192, kernel_size=5, stride=1, padding=2),\n","                      nn.ReLU(inplace=True),\n","                      nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n","                      nn.ReLU(inplace=True),\n","                      nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n","                      nn.ReLU(inplace=True),\n","                      nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n","                      nn.Dropout(0.5),\n","\n","                      nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1),\n","                      nn.ReLU(inplace=True),\n","                      nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n","                      nn.ReLU(inplace=True),\n","                      nn.Conv2d(192,  self.num_classes , kernel_size=1, stride=1, padding=0),\n","                      nn.ReLU(inplace=True),\n","                      nn.AvgPool2d(kernel_size=8, stride=1, padding=0),\n","                      )\n","\n","  def forward(self, x):\n","    x = self.classifier(x)\n","    x = x.view(x.size(0), self.num_classes)\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ObXs8cj2L5Io","colab_type":"text"},"source":["# Initializing weights and bias"]},{"cell_type":"code","metadata":{"id":"HcYid_IfMHzD","colab_type":"code","colab":{}},"source":["model = Net()\n","model.cuda()\n","\n","pretrained=False\n","if pretrained:\n","    params = pickle.load(open('data/params', 'r'))\n","    index = -1\n","    for m in model.modules():\n","        if isinstance(m, nn.Conv2d):\n","            index = index + 1\n","            weight = torch.from_numpy(params[index])\n","            m.weight.data.copy_(weight)\n","            index = index + 1\n","            bias = torch.from_numpy(params[index])\n","            m.bias.data.copy_(bias)\n","else:\n","    for m in model.modules():\n","        if isinstance(m, nn.Conv2d):\n","            m.weight.data.normal_(0, 0.05)\n","            m.bias.data.normal_(0, 0.0)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FMfiYInuMOXv","colab_type":"text"},"source":["# Splitting Model into sections for discriminative learning"]},{"cell_type":"code","metadata":{"id":"n9KML_u2afwe","colab_type":"code","colab":{}},"source":["learn = Learner(data, model, loss_func= loss_func, opt_func = opt_func ,metrics=metrics).mixup()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UBs1iGqzsuKv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"53c4f147-ec59-4f0e-815e-d820a56a2e41","executionInfo":{"status":"ok","timestamp":1563276370463,"user_tz":-330,"elapsed":32687,"user":{"displayName":"shuba shri","photoUrl":"https://lh3.googleusercontent.com/-6mf_1I_GK0M/AAAAAAAAAAI/AAAAAAAAAAw/L162wbYPd1w/s64/photo.jpg","userId":"07429367993324851323"}}},"source":["learn.split([[ learn.model.classifier[0:20]], [learn.model.classifier[20] ]])"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Learner(data=ImageDataBunch;\n","\n","Train: LabelList (50000 items)\n","x: ImageList\n","Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32)\n","y: CategoryList\n","otter,otter,otter,otter,otter\n","Path: /root/.fastai/data/cifar100;\n","\n","Valid: LabelList (10000 items)\n","x: ImageList\n","Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32)\n","y: CategoryList\n","otter,otter,otter,otter,otter\n","Path: /root/.fastai/data/cifar100;\n","\n","Test: None, model=Net(\n","  (classifier): Sequential(\n","    (0): Conv2d(3, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (1): ReLU(inplace)\n","    (2): Conv2d(192, 160, kernel_size=(1, 1), stride=(1, 1))\n","    (3): ReLU(inplace)\n","    (4): Conv2d(160, 96, kernel_size=(1, 1), stride=(1, 1))\n","    (5): ReLU(inplace)\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (7): Dropout(p=0.5)\n","    (8): Conv2d(96, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (9): ReLU(inplace)\n","    (10): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n","    (11): ReLU(inplace)\n","    (12): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n","    (13): ReLU(inplace)\n","    (14): AvgPool2d(kernel_size=3, stride=2, padding=1)\n","    (15): Dropout(p=0.5)\n","    (16): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (17): ReLU(inplace)\n","    (18): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n","    (19): ReLU(inplace)\n","    (20): Conv2d(192, 100, kernel_size=(1, 1), stride=(1, 1))\n","    (21): ReLU(inplace)\n","    (22): AvgPool2d(kernel_size=8, stride=1, padding=0)\n","  )\n","), opt_func=functools.partial(<class 'torch.optim.sgd.SGD'>, momentum=0.9), loss_func=CrossEntropyLoss(), metrics=[<function accuracy at 0x7f67b943f0d0>, <function error_rate at 0x7f67b943f2f0>, <function top_k_accuracy at 0x7f67b943f1e0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/root/.fastai/data/cifar100'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.4, stack_x=False, stack_y=True)], callbacks=[], layer_groups=[Sequential(\n","  (0): Sequential(\n","    (0): Conv2d(3, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (1): ReLU(inplace)\n","    (2): Conv2d(192, 160, kernel_size=(1, 1), stride=(1, 1))\n","    (3): ReLU(inplace)\n","    (4): Conv2d(160, 96, kernel_size=(1, 1), stride=(1, 1))\n","    (5): ReLU(inplace)\n","    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (7): Dropout(p=0.5)\n","    (8): Conv2d(96, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (9): ReLU(inplace)\n","    (10): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n","    (11): ReLU(inplace)\n","    (12): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n","    (13): ReLU(inplace)\n","    (14): AvgPool2d(kernel_size=3, stride=2, padding=1)\n","    (15): Dropout(p=0.5)\n","    (16): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (17): ReLU(inplace)\n","    (18): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n","    (19): ReLU(inplace)\n","  )\n","), Sequential(\n","  (0): Conv2d(192, 100, kernel_size=(1, 1), stride=(1, 1))\n",")], add_time=True, silent=False)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"hnLRNWL9MToc","colab_type":"text"},"source":["# Decalring Step Dropout as Callback\n","\n"]},{"cell_type":"code","metadata":{"id":"byf9ZSraA5MZ","colab_type":"code","colab":{}},"source":["class Drop_Activations(LearnerCallback):\n","  train_flag = False\n","  \n","  def on_train_begin(self, **kwargs):\n","    \"Initialize stats.\"\n","    super().on_train_begin(**kwargs)\n","    self.train_flag = True\n","    \n","  def on_epoch_begin(self, **kwargs):\n","    if (self.train_flag):\n","      epoch_num = kwargs['epoch']\n","      epoch_tot = kwargs['n_epochs']\n","\n","      child = children(self.model)[0]\n","      for item in child:\n","        if isinstance(item, nn.Dropout):\n","          item.p = (epoch_num  / epoch_tot) * 0.5\n","\n","  def on_train_end(self, **kwargs):\n","    \"Initialize stats.\"\n","    super().on_train_begin(**kwargs)\n","    self.train_flag = False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3usmfeiZMu31","colab_type":"text"},"source":["# Using the step dropout in this notebook"]},{"cell_type":"code","metadata":{"id":"s7GkZ8ajMqjL","colab_type":"code","colab":{}},"source":["learn.callbacks += [ Drop_Activations(learn) ]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B5fz5C-KM3On","colab_type":"text"},"source":["# Running the Network"]},{"cell_type":"code","metadata":{"id":"P48QhLSTKQWL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f80d0866-e563-4bd8-c5c1-c56560922df8","executionInfo":{"status":"ok","timestamp":1563277747871,"user_tz":-330,"elapsed":351924,"user":{"displayName":"shuba shri","photoUrl":"https://lh3.googleusercontent.com/-6mf_1I_GK0M/AAAAAAAAAAI/AAAAAAAAAAw/L162wbYPd1w/s64/photo.jpg","userId":"07429367993324851323"}}},"source":["learn.fit( 40 ,  lr= (1 * base_lr , 0.1 * base_lr) , wd = (2 * w_decay , 1 *w_decay))"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='36' class='' max='40', style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      90.00% [36/40 20:41<02:17]\n","    </div>\n","    \n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>error_rate</th>\n","      <th>top_k_accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>4.477996</td>\n","      <td>4.432767</td>\n","      <td>0.027800</td>\n","      <td>0.972200</td>\n","      <td>0.142900</td>\n","      <td>00:34</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>4.297046</td>\n","      <td>4.173907</td>\n","      <td>0.070900</td>\n","      <td>0.929100</td>\n","      <td>0.243300</td>\n","      <td>00:33</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>4.152416</td>\n","      <td>3.915993</td>\n","      <td>0.101400</td>\n","      <td>0.898600</td>\n","      <td>0.313200</td>\n","      <td>00:33</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>3.982190</td>\n","      <td>3.759217</td>\n","      <td>0.120300</td>\n","      <td>0.879700</td>\n","      <td>0.351200</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>3.833276</td>\n","      <td>3.510408</td>\n","      <td>0.158700</td>\n","      <td>0.841300</td>\n","      <td>0.420000</td>\n","      <td>00:33</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>3.724839</td>\n","      <td>3.300355</td>\n","      <td>0.203500</td>\n","      <td>0.796500</td>\n","      <td>0.485500</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>3.609060</td>\n","      <td>3.275402</td>\n","      <td>0.202400</td>\n","      <td>0.797600</td>\n","      <td>0.494600</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>3.468804</td>\n","      <td>2.966768</td>\n","      <td>0.268600</td>\n","      <td>0.731400</td>\n","      <td>0.576300</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>3.365316</td>\n","      <td>2.747127</td>\n","      <td>0.307100</td>\n","      <td>0.692900</td>\n","      <td>0.627200</td>\n","      <td>00:32</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>3.241804</td>\n","      <td>2.639326</td>\n","      <td>0.328100</td>\n","      <td>0.671900</td>\n","      <td>0.639300</td>\n","      <td>00:34</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>3.201501</td>\n","      <td>2.604807</td>\n","      <td>0.341100</td>\n","      <td>0.658900</td>\n","      <td>0.657400</td>\n","      <td>00:34</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>3.110262</td>\n","      <td>2.441826</td>\n","      <td>0.375300</td>\n","      <td>0.624700</td>\n","      <td>0.693500</td>\n","      <td>00:36</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>2.998273</td>\n","      <td>2.313722</td>\n","      <td>0.403200</td>\n","      <td>0.596800</td>\n","      <td>0.711500</td>\n","      <td>00:36</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>2.951674</td>\n","      <td>2.263747</td>\n","      <td>0.413300</td>\n","      <td>0.586700</td>\n","      <td>0.721700</td>\n","      <td>00:36</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>2.908578</td>\n","      <td>2.145381</td>\n","      <td>0.436800</td>\n","      <td>0.563200</td>\n","      <td>0.742700</td>\n","      <td>00:36</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>2.858315</td>\n","      <td>2.084940</td>\n","      <td>0.458400</td>\n","      <td>0.541600</td>\n","      <td>0.756900</td>\n","      <td>00:35</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>2.781051</td>\n","      <td>2.076110</td>\n","      <td>0.458100</td>\n","      <td>0.541900</td>\n","      <td>0.759000</td>\n","      <td>00:34</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>2.776512</td>\n","      <td>2.000367</td>\n","      <td>0.475000</td>\n","      <td>0.525000</td>\n","      <td>0.777500</td>\n","      <td>00:35</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>2.732505</td>\n","      <td>2.014058</td>\n","      <td>0.468900</td>\n","      <td>0.531100</td>\n","      <td>0.774100</td>\n","      <td>00:33</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>2.687586</td>\n","      <td>1.930447</td>\n","      <td>0.489300</td>\n","      <td>0.510700</td>\n","      <td>0.787100</td>\n","      <td>00:33</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>2.649626</td>\n","      <td>1.883950</td>\n","      <td>0.504300</td>\n","      <td>0.495700</td>\n","      <td>0.797400</td>\n","      <td>00:33</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>2.617248</td>\n","      <td>1.843381</td>\n","      <td>0.511900</td>\n","      <td>0.488100</td>\n","      <td>0.802500</td>\n","      <td>00:33</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>2.593030</td>\n","      <td>1.772750</td>\n","      <td>0.525500</td>\n","      <td>0.474500</td>\n","      <td>0.810200</td>\n","      <td>00:33</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>2.586030</td>\n","      <td>1.799843</td>\n","      <td>0.531200</td>\n","      <td>0.468800</td>\n","      <td>0.808400</td>\n","      <td>00:33</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>2.567034</td>\n","      <td>1.778071</td>\n","      <td>0.528500</td>\n","      <td>0.471500</td>\n","      <td>0.815900</td>\n","      <td>00:33</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>2.552400</td>\n","      <td>1.758896</td>\n","      <td>0.535100</td>\n","      <td>0.464900</td>\n","      <td>0.817300</td>\n","      <td>00:37</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>2.533973</td>\n","      <td>1.660694</td>\n","      <td>0.550000</td>\n","      <td>0.450000</td>\n","      <td>0.833900</td>\n","      <td>00:35</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>2.541880</td>\n","      <td>1.751707</td>\n","      <td>0.533500</td>\n","      <td>0.466500</td>\n","      <td>0.816300</td>\n","      <td>00:34</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>2.526311</td>\n","      <td>1.709885</td>\n","      <td>0.546000</td>\n","      <td>0.454000</td>\n","      <td>0.827200</td>\n","      <td>00:34</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>2.494912</td>\n","      <td>1.706073</td>\n","      <td>0.541500</td>\n","      <td>0.458500</td>\n","      <td>0.823400</td>\n","      <td>00:38</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>2.530396</td>\n","      <td>1.742901</td>\n","      <td>0.532600</td>\n","      <td>0.467400</td>\n","      <td>0.821100</td>\n","      <td>00:34</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>2.503664</td>\n","      <td>1.759520</td>\n","      <td>0.535200</td>\n","      <td>0.464800</td>\n","      <td>0.815200</td>\n","      <td>00:33</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>2.477015</td>\n","      <td>1.618561</td>\n","      <td>0.568500</td>\n","      <td>0.431500</td>\n","      <td>0.839400</td>\n","      <td>00:34</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>2.462437</td>\n","      <td>1.639865</td>\n","      <td>0.566500</td>\n","      <td>0.433500</td>\n","      <td>0.833800</td>\n","      <td>00:35</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>2.472082</td>\n","      <td>1.639359</td>\n","      <td>0.564800</td>\n","      <td>0.435200</td>\n","      <td>0.830100</td>\n","      <td>00:34</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>2.482987</td>\n","      <td>1.599746</td>\n","      <td>0.571300</td>\n","      <td>0.428700</td>\n","      <td>0.839600</td>\n","      <td>00:34</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='379' class='' max='390', style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      97.18% [379/390 00:29<00:00 2.4646]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JAmxTrm4RllL","colab_type":"text"},"source":["# Results"]},{"cell_type":"code","metadata":{"id":"oenZFegWLfYX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"16bf248f-3574-4b4a-a099-53fab184e328","executionInfo":{"status":"ok","timestamp":1563277752000,"user_tz":-330,"elapsed":28,"user":{"displayName":"shuba shri","photoUrl":"https://lh3.googleusercontent.com/-6mf_1I_GK0M/AAAAAAAAAAI/AAAAAAAAAAw/L162wbYPd1w/s64/photo.jpg","userId":"07429367993324851323"}}},"source":["learn.validate()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1.5717146, tensor(0.5796), tensor(0.4204), tensor(0.8477)]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"qNRXffhQRjWa","colab_type":"text"},"source":["# Best Results :\n","\n","[Obtained during trial run. I hope the variation is minimal across multiple runs]\n","\n","> train_loss --------------------------------- 2.445148\n","\n","> valid_loss --------------------------------- 1.571715\n","\n","> accuracy ---------------------------------- 0.5796\n","\n","> error_rate --------------------------------- 0.4204\n","\n","> top_k_accuracy -----------------------  0.8477\n","\n"]}]}